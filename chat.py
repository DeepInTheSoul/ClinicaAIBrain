# UIæ¡†æ¶
import os  # å¯¼å…¥æ“ä½œç³»ç»Ÿæ¨¡å—
import streamlit as st  # å¯¼å…¥ Streamlit å¹¶ç®€å†™ä¸º st
from rag import rag_chain, rag_chain_v2  # ä» rag æ¨¡å—å¯¼å…¥ rag_chain å‡½æ•°
from dotenv import dotenv_values  # ä» dotenv æ¨¡å—å¯¼å…¥ dotenv_values å‡½æ•°
from langchain_openai import ChatOpenAI  # ä» langchain_openai æ¨¡å—å¯¼å…¥ ChatOpenAI
from langchain_community.llms import QianfanLLMEndpoint  # ä» langchain_community.llms æ¨¡å—å¯¼å…¥ QianfanLLMEndpoint

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
config = dotenv_values(".env")

# è®¾ç½® Qianfan çš„ AK å’Œ SK ç¯å¢ƒå˜é‡
os.environ["QIANFAN_AK"] = "rYndCW8UyNrh7ZIxAmxG0w1X"
os.environ["QIANFAN_SK"] = "KovKWoaJeKYeIQwLgOUxFof5KI1ggTRq"

# åˆå§‹åŒ–ä¸åŒçš„å¤§æ¨¡å‹æ¥å£
ERNIE4_llm = QianfanLLMEndpoint(model="ERNIE-4.0-8K", streaming=False)
Yi_llm = QianfanLLMEndpoint(model="Yi-34B-Chat", streaming=False)
Llama_llm = QianfanLLMEndpoint(model="Meta-Llama-3-8B", streaming=False)
ChatGLM_llm = QianfanLLMEndpoint(model="ChatGLM2-6B-32K", streaming=False)

# å®šä¹‰èŠå¤©é¡µé¢å‡½æ•°
def chat_page():
    # UIç•Œé¢çš„è¾¹æ ï¼Œé€šè¿‡ä¸‹æ‹‰åˆ—è¡¨åˆ‡æ¢LLMæ¨¡å‹
    with st.sidebar:
        pattern_list = [
            "å¤§æ¨¡å‹é—®ç­”",  # å¯¹è¯æ¨¡å¼é€‰é¡¹
            "åŒ»ç–—çŸ¥è¯†åº“é—®ç­”",
        ]

        model_list = [
            "æ–‡å¿ƒä¸€è¨€4.0",  # å¯¹è¯æ¨¡å‹é€‰é¡¹
            "ChatGLM-6B",
            "Llama3-8B",
            "Yi-34B",
        ]
        pattern = st.selectbox("å¯¹è¯æ¨¡å¼é€‰æ‹©ï¼š",  # åˆ›å»ºé€‰æ‹©æ¡†ä¾›ç”¨æˆ·é€‰æ‹©å¯¹è¯æ¨¡å¼
                             pattern_list,
                             index=0
                             )
        st.write('You selected:', pattern)  # æ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„å¯¹è¯æ¨¡å¼

        model = st.selectbox("å¯¹è¯æ¨¡å‹é€‰æ‹©ï¼š",  # åˆ›å»ºé€‰æ‹©æ¡†ä¾›ç”¨æˆ·é€‰æ‹©å¯¹è¯æ¨¡å‹
                             model_list,
                             index=0
                             )
        st.write('You selected:', model)  # æ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„å¯¹è¯æ¨¡å‹

    st.title("ğŸ¤– ClinicaAIBrainï¼šæ™ºèƒ½åŒ»ç–—å¤§è„‘")  # è®¾ç½®é¡µé¢æ ‡é¢˜
    # èŠå¤©å†å²è®°å½•åˆå§‹åŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # èŠå¤©ç•Œé¢å±•ç¤ºå†å²èŠå¤©
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
             st.markdown(message["content"])

    # æ ¹æ®é€‰æ‹©çš„å¯¹è¯æ¨¡å¼å’Œæ¨¡å‹ï¼Œåˆå§‹åŒ–å¯¹åº”çš„ LLM å®ä¾‹
    if pattern == "å¤§æ¨¡å‹é—®ç­”":
        if model == "æ–‡å¿ƒä¸€è¨€4.0":
            llm = ERNIE4_llm
        elif model == "ChatGLM-6B":
            llm = ChatGLM_llm
        elif model == "Llama3-8B":
            llm = Llama_llm
        elif model == "Yi-34B":
            llm = Yi_llm
    elif pattern == "åŒ»ç–—çŸ¥è¯†åº“é—®ç­”":
        if model == "æ–‡å¿ƒä¸€è¨€4.0":
            llm = rag_chain(ERNIE4_llm)
        elif model == "ChatGLM-6B":
            llm = rag_chain(ChatGLM_llm)
        elif model == "Llama3-8B":
            llm = rag_chain(Llama_llm)
        elif model == "Yi-34B":
            llm = rag_chain(Yi_llm)

    # è·å–ç”¨æˆ·è¾“å…¥çš„èŠå¤©æ¶ˆæ¯
    if chat_input := st.chat_input("What is up?"):
        st.chat_message("user").markdown(chat_input)  # åœ¨èŠå¤©ç•Œé¢æ˜¾ç¤ºç”¨æˆ·çš„æ¶ˆæ¯
        # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•
        st.session_state.messages.append({"role": "user", "content": chat_input})
        with st.chat_message("assistant"):
            # ä»¥æµå¼è¾“å‡ºçš„æ–¹å¼è°ƒç”¨ LLM çš„ APIï¼Œå¹¶åœ¨ UI ç•Œé¢æ˜¾ç¤º
            response = st.write_stream(
                llm.stream(chat_input))
        # å°†å¤§æ¨¡å‹çš„æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•
        st.session_state.messages.append({"role": "assistant", "content": response})



# å®šä¹‰èŠå¤©é¡µé¢å‡½æ•°
def chat_page_v2():
    # UIç•Œé¢çš„è¾¹æ ï¼Œé€šè¿‡ä¸‹æ‹‰åˆ—è¡¨åˆ‡æ¢LLMæ¨¡å‹
    with st.sidebar:
        pattern_list = [
            "åŒ»ç–—çŸ¥è¯†åº“é—®ç­”",
        ]

        model_list = [
            "æ–‡å¿ƒä¸€è¨€4.0",  # å¯¹è¯æ¨¡å‹é€‰é¡¹
            "ChatGLM-6B",
            "Llama3-8B",
            "Yi-34B",
        ]
        pattern = st.selectbox("å¯¹è¯æ¨¡å¼é€‰æ‹©ï¼š",  # åˆ›å»ºé€‰æ‹©æ¡†ä¾›ç”¨æˆ·é€‰æ‹©å¯¹è¯æ¨¡å¼
                             pattern_list,
                             index=0
                             )
        st.write('You selected:', pattern)  # æ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„å¯¹è¯æ¨¡å¼

        model = st.selectbox("å¯¹è¯æ¨¡å‹é€‰æ‹©ï¼š",  # åˆ›å»ºé€‰æ‹©æ¡†ä¾›ç”¨æˆ·é€‰æ‹©å¯¹è¯æ¨¡å‹
                             model_list,
                             index=0
                             )
        st.write('You selected:', model)  # æ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„å¯¹è¯æ¨¡å‹

    st.title("ğŸ¤– ClinicaAIBrainï¼šæ™ºèƒ½åŒ»ç–—å¤§è„‘")  # è®¾ç½®é¡µé¢æ ‡é¢˜
    # èŠå¤©å†å²è®°å½•åˆå§‹åŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # èŠå¤©ç•Œé¢å±•ç¤ºå†å²èŠå¤©
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
             st.markdown(message["content"])

    # æ ¹æ®é€‰æ‹©çš„å¯¹è¯æ¨¡å¼å’Œæ¨¡å‹ï¼Œåˆå§‹åŒ–å¯¹åº”çš„ LLM å®ä¾‹
    if pattern == "å¤§æ¨¡å‹é—®ç­”":
        if model == "æ–‡å¿ƒä¸€è¨€4.0":
            llm = ERNIE4_llm
        elif model == "ChatGLM-6B":
            llm = ChatGLM_llm
        elif model == "Llama3-8B":
            llm = Llama_llm
        elif model == "Yi-34B":
            llm = Yi_llm
    elif pattern == "åŒ»ç–—çŸ¥è¯†åº“é—®ç­”":
        if model == "æ–‡å¿ƒä¸€è¨€4.0":
            llm = ERNIE4_llm
        elif model == "ChatGLM-6B":
            llm = ChatGLM_llm
        elif model == "Llama3-8B":
            llm = Llama_llm
        elif model == "Yi-34B":
            llm = Yi_llm

    # è·å–ç”¨æˆ·è¾“å…¥çš„èŠå¤©æ¶ˆæ¯
    if chat_input := st.chat_input("What is up?"):
        st.chat_message("user").markdown(chat_input)  # åœ¨èŠå¤©ç•Œé¢æ˜¾ç¤ºç”¨æˆ·çš„æ¶ˆæ¯
        # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•
        st.session_state.messages.append({"role": "user", "content": chat_input})
        with st.chat_message("assistant"):
            # ä»¥æµå¼è¾“å‡ºçš„æ–¹å¼è°ƒç”¨ LLM çš„ APIï¼Œå¹¶åœ¨ UI ç•Œé¢æ˜¾ç¤º
            response = st.write(
                rag_chain_v2(llm,chat_input))
        # å°†å¤§æ¨¡å‹çš„æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•
        st.session_state.messages.append({"role": "assistant", "content": response})